{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1-izC4ZKHJ9"
      },
      "source": [
        "<h1 style=\"text-align: center\">\n",
        "Machine Learning HW1 </br>\n",
        "MLE & MAP in Python\n",
        "</h1>\n",
        "\n",
        "#### Name: Ehasan Hassanbeygi\n",
        "\n",
        "#### Std. Number: 402211723"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhTuYwHYbE_1"
      },
      "source": [
        "## Objective\n",
        "This exercise will help you gain a deeper understanding of, and insights into, Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP) estimation$\\textit{Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP) }$ :) \\\\\n",
        "Let’s say you have a barrel of apples that are all different sizes. You pick an apple at random, and you want to know its weight. Unfortunately, all you have is a broken scale. answer the questions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSaLb6AYa9DJ"
      },
      "source": [
        "1) For the sake of this section, lets imagine a farmer tells you that the scale returns the weight of the object with an error of +/- a standard deviation of 5g. We can describe this mathematically as:\n",
        "$$\n",
        "measurement = weight + \\mathcal{N}(0, 5g)\n",
        "$$\n",
        "You can weigh the apple as many times as you want, so weigh it 100 times.\n",
        "plot its histogram of your 100 measurements. (y axis is the counts and x-axis is the measured weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hPMnHTcia07a"
      },
      "outputs": [],
      "source": [
        "        ######################################################\n",
        "        ###################### TO DO #########################\n",
        "        ######################################################\n",
        "        #                                                    #\n",
        "        #                                                    #\n",
        "        ######################################################\n",
        "        ######################################################\n",
        "        ######################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD9Mqy-bcPi5"
      },
      "source": [
        "2) Find the average weight of the apple.\n",
        "Is it a good guess? state your reason."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xlCBTC0lcPKa"
      },
      "outputs": [],
      "source": [
        "        ######################################################\n",
        "        ###################### TO DO #########################\n",
        "        ######################################################\n",
        "        #                                                    #\n",
        "        #                                                    #\n",
        "        ######################################################\n",
        "        ######################################################\n",
        "        ######################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-P9PJuKcrbq"
      },
      "source": [
        "3) we are going to use grid approximation for calculating the MLE. here is the link if you wnat to get more fimilar with this technique:\n",
        "https://www.bayesrulesbook.com/chapter-6\n",
        "\n",
        "Our end goal is to find the weight of the apple, given the data we have. To formulate it in a Bayesian way: We’ll ask what is the probability of the apple having weight, $w$, given the measurements we took, $X$. And, because we're formulating this in a Bayesian way, we use Bayes’ Law to find the answer:\n",
        "\n",
        "$$\n",
        "P(w|X) = \\frac{P(X|w)P(w)}{P(X)}\n",
        "$$\n",
        "\n",
        "If we make no assumptions about the initial weight of our apple, then we can drop $P(w)$. We’ll say all sizes of apples are equally likely (we’ll revisit this assumption in the MAP approximation).\n",
        "\n",
        "Furthermore, we’ll drop $P(X)$ - the probability of seeing our data. This is a normalization constant and will be important if we do want to know the probabilities of apple weights. But, for right now, our end goal is to only to find the most probable weight. $P(X)$ is independent of $w$, so we can drop it if we’re doing relative comparisons.\n",
        "\n",
        "This leaves us with $P(X|w)$, our likelihood, as in, what is the likelihood that we would see the data, $X$, given an apple of weight $w$. If we maximize this, we maximize the probability that we will guess the right weight.\n",
        "\n",
        "The grid approximation is probably the simplest way to do this. Basically, we’ll systematically step through different weight guesses, and compare what it would look like if this hypothetical weight were to generate data. We’ll compare this hypothetical data to our real data and pick the one that matches the best.\n",
        "\n",
        "To formulate this mathematically:\n",
        "\n",
        "For each of these guesses, we’re asking \"what is the probability that the data we have, came from the distribution that our weight guess would generate\". Because each measurement is independent from another, we can break the above equation down into finding the probability on a per measurement basis:\n",
        "\n",
        "$$\n",
        "P(X|w) = \\prod_{i}^{N} p(x_i|w)\n",
        "$$\n",
        "\n",
        "So, if we multiply the probability that we would see each individual data point - given our weight guess - then we can find one number comparing our weight guess to all of our data.\n",
        "\n",
        "The peak in the likelihood is the weight of the apple.\n",
        "\n",
        "To make it computationally easier,\n",
        "\n",
        "$$\n",
        "\\log P(X|w) = \\log \\prod_{i}^{N} p(x_i|w) = \\sum_{i}^{N} \\log p(d_i|w)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "a) Why did we use log likelihood? Is it ok to do so?\n",
        "\n",
        "b) do the grid approximation and complete the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9NnWmxzTiRfr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  0.           2.04081633   4.08163265   6.12244898   8.16326531\n",
            "  10.20408163  12.24489796  14.28571429  16.32653061  18.36734694\n",
            "  20.40816327  22.44897959  24.48979592  26.53061224  28.57142857\n",
            "  30.6122449   32.65306122  34.69387755  36.73469388  38.7755102\n",
            "  40.81632653  42.85714286  44.89795918  46.93877551  48.97959184\n",
            "  51.02040816  53.06122449  55.10204082  57.14285714  59.18367347\n",
            "  61.2244898   63.26530612  65.30612245  67.34693878  69.3877551\n",
            "  71.42857143  73.46938776  75.51020408  77.55102041  79.59183673\n",
            "  81.63265306  83.67346939  85.71428571  87.75510204  89.79591837\n",
            "  91.83673469  93.87755102  95.91836735  97.95918367 100.        ]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\n# Calculate the maximum likelihood estimate of a parameter in a normal distribution.\\n# First calculate the log likelihoods for a range of weight guesses.\\n# For each weight guess, assume that the data comes from a normal distribution with that mean and a standard deviation of 10.\\n# Then calculate the log of the probability density function (pdf) of the data under this assumption.\\n# The sum of these log pdf values is the total log likelihood for that weight guess.\\n# After calculating the log likelihoods for all weight guesses, find the weight guess with the maximum log likelihood.\\n# This is the maximum likelihood estimate of the weight.\\n'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.stats import norm\n",
        "import numpy as np\n",
        "\n",
        "weight_grid = np.linspace(0, 100)\n",
        "print(weight_grid)\n",
        "\n",
        "            ######################################################\n",
        "        ###################### TO DO #########################\n",
        "        ######################################################\n",
        "        #                                                    #\n",
        "        #                                                    #\n",
        "        ######################################################\n",
        "        ######################################################\n",
        "        ######################################################\n",
        "\n",
        "\"\"\"\n",
        "# Calculate the maximum likelihood estimate of a parameter in a normal distribution.\n",
        "# First calculate the log likelihoods for a range of weight guesses.\n",
        "# For each weight guess, assume that the data comes from a normal distribution with that mean and a standard deviation of 10.\n",
        "# Then calculate the log of the probability density function (pdf) of the data under this assumption.\n",
        "# The sum of these log pdf values is the total log likelihood for that weight guess.\n",
        "# After calculating the log likelihoods for all weight guesses, find the weight guess with the maximum log likelihood.\n",
        "# This is the maximum likelihood estimate of the weight.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN3lt2npcc2S"
      },
      "source": [
        "Play around with the code and try to answer the following questions regarding MLE and MAP. You can draw plots to visualize as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ezcWTpNQamCL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average measurement: 114.854 g\n",
            "Maximum Likelihood estimate: 115.576 g\n",
            "Maximum A Posterior estimate: 113.566 g\n",
            "The true weight of the apple was: 114.398 g\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm, invgamma\n",
        "\n",
        "\n",
        "# The barrel of apples\n",
        "# The average apples is between 70-100 g\n",
        "BARREL = np.random.normal(loc=85, scale=20, size=100)\n",
        "# Grid\n",
        "WEIGHT_GUESSES = np.linspace(1, 200, 100)\n",
        "ERROR_GUESSES = np.linspace(.1, 50, 100)\n",
        "\n",
        "# NOTE: Try changing the scale error\n",
        "# in practice, you would not know this number\n",
        "SCALE_ERR = 5\n",
        "\n",
        "# NOTE: Try changing the number of measurements taken\n",
        "N_MEASURMENTS = 10\n",
        "\n",
        "# NOTE: Try changing the prior values and distributions\n",
        "PRIOR_WEIGHT = norm(50, 1).logpdf(WEIGHT_GUESSES)\n",
        "PRIOR_ERR = invgamma(4).logpdf(ERROR_GUESSES)\n",
        "\n",
        "LOG_PRIOR_GRID = np.add.outer(PRIOR_ERR, PRIOR_WEIGHT)\n",
        "\n",
        "\n",
        "def read_scale(apple):\n",
        "    return apple + np.random.normal(loc=0, scale=SCALE_ERR)\n",
        "\n",
        "\n",
        "def get_log_likelihood_grid(measurments):\n",
        "    log_liklelihood = [\n",
        "        [\n",
        "            norm(weight_guess, error_guess).logpdf(measurments).sum()\n",
        "            for weight_guess in WEIGHT_GUESSES\n",
        "        ]\n",
        "        for error_guess in ERROR_GUESSES\n",
        "    ]\n",
        "    return np.asarray(log_liklelihood)\n",
        "\n",
        "\n",
        "def get_mle(measurements):\n",
        "    \"\"\"\n",
        "    Calculate the log-likelihood for each measurement in the grid.\n",
        "    Find the index of the maximum log-likelihood in the grid.\n",
        "    Return the weight guess corresponding to the maximum log-likelihood.\n",
        "    \"\"\"\n",
        "    ll_grid = get_log_likelihood_grid(measurements)\n",
        "\n",
        "    sigma_hat_index, mu_hat_index = np.unravel_index(np.argmax(ll_grid), ll_grid.shape)\n",
        "    # print(norm(WEIGHT_GUESSES[mu_hat_index], ERROR_GUESSES[sigma_hat_index]).logpdf(measurments).sum())\n",
        "    # print(ll_grid[(sigma_hat_index, mu_hat_index)])\n",
        "    return WEIGHT_GUESSES[mu_hat_index]\n",
        "\n",
        "\n",
        "def get_map(measurements):\n",
        "    \"\"\"\n",
        "    Calculate the log-likelihood for each measurement in the grid.\n",
        "    Add the log prior to the log likelihood to get the log posterior.\n",
        "    Find the index of the maximum log posterior in the grid.\n",
        "    Return the weight guess corresponding to the maximum log posterior.\n",
        "    \"\"\"\n",
        "    ll_grid = get_log_likelihood_grid(measurements)\n",
        "    sigma_hat_index, mu_hat_index = np.unravel_index(np.argmax(ll_grid+LOG_PRIOR_GRID.T), ll_grid.shape)\n",
        "\n",
        "    return WEIGHT_GUESSES[mu_hat_index]\n",
        "\n",
        "\n",
        "# Pick an apple at random\n",
        "apple = np.random.choice(BARREL)\n",
        "\n",
        "# weight the apple\n",
        "measurments = np.asarray([read_scale(apple) for _ in range(N_MEASURMENTS)])\n",
        "# ll_grid = get_log_likelihood_grid(measurments)\n",
        "# print(ll_grid)\n",
        "# print(np.max(ll_grid))\n",
        "# print(ll_grid.shape)\n",
        "\n",
        "print(f\"Average measurement: {measurments.mean():.3f} g\")\n",
        "print(f\"Maximum Likelihood estimate: {get_mle(measurments):.3f} g\")\n",
        "print(f\"Maximum A Posterior estimate: {get_map(measurments):.3f} g\")\n",
        "print(f\"The true weight of the apple was: {apple:.3f} g\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI_541TpetKk"
      },
      "source": [
        "<h3><i><i> Questions</h3>\n",
        "1.\n",
        "How sensitive is the MAP measurement to the choice of prior?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMV-wgYXes_O"
      },
      "source": [
        "<h3><i><i></h3>\n",
        "2. How sensitive is the MLE and MAP answer to the grid size?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
